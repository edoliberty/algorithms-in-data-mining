\documentclass{article}
\usepackage{algorithms_in_data_mining}

\begin{document} %

\lecture{1}{Mark and Recapture}{Edo Liberty}

Suppose you are a marine biologist (Although you prefer to pretend to be an architect) and
suppose you are tasked with counting the number of individuals in a huge school of fish in 
the middle of the Atlantic ocean. How would you go about doing that? 
One possible approach is called Mark and Recapture.
Start by catching $k$ fish. Then, mark them somehow 
and release them. Then catch another group of $k$ fish and count the number of fish that are already marked, $Z$.
You can now guess that the number of fish in the entire school is roughly $k^2/Z$.
Jacques Cousteau would have been proud.

\section*{Mark and Recapture}
Given a set of $n$ elements, sample $k$ without replacement twice.
Count the number of identical elements in both groups, $Z$.
Define a random variable $z_{i,j}$ which indicates that
element $i$ in the first group is the same as element $j$ in the second.
The value of $Z$ is therefore $Z = \sum_{i,j} z_{i,j}$.
Lets compute the expectation of $Z$ using linearity of expectation.
Note that the $z_{i,j}$ variables are not independent!
\begin{equation}
E[Z] = E[\sum_{i,j} z_{i,j}] = \sum_{i,j} E [z_{i,j}] = \sum_{i,j} 1/n = k^2/n
\end{equation}


%Using Markov we can bound the probability that $Z > 1$.
%\begin{equation}
%\Pr[Z > 1] = \Pr[Z \ge 2] \le E[Z]/2 = 1/2
%\end{equation}
%Also, using simple combinatorics we can estimate the probability that $Z=0$.
%For that, all $k$ users in the second group should succeed in missing the first group.
%These events are independent so:
%\begin{eqnarray}
%\Pr[Z =0] &=& \frac{n-k}{n}\cdot\frac{n-k-1}{n-1}\cdot\ldots\cdot\frac{n-k-k}{n-k} \\
%&\le& \left(\frac{n-2k}{n}\right)^k = \left(1 - \frac{2k}{n}\right)^{(n/2k)(2k^2/n)} \le e^{-2}
%\end{eqnarray}
%
%This gives us the desired result that if we sample $k = \sqrt{n}$ users for each group we will have exactly one collision
%with probability at least $\Pr[Z=1] \ge 1 - 1/2 - e^{-1} \approx 0.13$

\noindent Lets compute the standard deviation of $Z$. Recall:
$$\sigma^2[Z]  = E[Z-E[Z]]^2= E[Z^2] - E[Z]^2$$

\noindent  We need the use the linearity of expectation again to compute $E[Z^2]$:
\begin{eqnarray}
E[Z^2] &=& E[(\sum_{i,j} z_{i,j})(\sum_{i',j'} z_{i',j'})] \\ 
&=& \sum_{i=i',j=j'} E[z_{i,j}z_{i',j'}] \\
& & + \sum_{i=i', j \ne j'} E[z_{i,j}z_{i',j'}] +\sum_{i \ne i', j = j'} E[z_{i,j}z_{i',j'}]  \\
& & + \sum_{i \ne i', j \ne j'} E[z_{i,j}z_{i',j'}] \\
& = & \frac{k^2}{n} + 0 + 0 + \frac{k^2(k-1)^2}{n^2} \\
\sigma^2[Z] &=& \frac{k^2}{n} + \frac{k^2(k-1)^2}{n^2} - \left(\frac{k^2}{n}\right)^2 \\
&\le& \frac{m^2}{n}  
\end{eqnarray}

\noindent  Now we invoke Chebyshev's inequality.
\begin{equation}
\Pr[|Z - \frac{k^2}{n}| > t] \le \frac{k^2}{nt^2}
\end{equation}

\noindent Choosing $t = 10k/\sqrt{n}$ we get that with probability at least $0.99$
\begin{equation}
|Z - \frac{k^2}{n}| \le 10k/\sqrt{n}
\end{equation}
Which gives:
\begin{eqnarray}
n &\le& \frac{k^2}{Z}(1+\frac{10\sqrt{n}}{k}) \\
n &\ge& \frac{k^2}{Z}(1-\frac{10\sqrt{n}}{k})
\end{eqnarray}


\noindent This gives us the following procedure:
First, sample $2$ groups of size $k \ge 50\sqrt{n}$ each.
Count the number of collision $Z$.
Estimate the size of the set as $n_{alg} = k^2/Z$.
We are guarantied that with probability $0.99$ our estimate is within $20\%$ accuracy.
\begin{equation}
\frac{5}{6}n \le n_{alg} \le \frac{5}{4}n
\end{equation}


\end{document}

